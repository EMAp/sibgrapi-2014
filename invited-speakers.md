---
layout: content
title: Invited Speakers
---

## Computational Analysis in Cultural Heritage Applications

- [Tim Weyrich](http://www0.cs.ucl.ac.uk/staff/t.weyrich/), University College London - UK

Through the increasing availability of high-quality consumer hardware
for advanced imaging tasks, digital imaging and scanning are gradually
pervading general practice in cultural heritage preservation and
archaeology. In most cases, however, imaging and scanning are
predominantly means of documentation and archival, and digital
processing ends with the creation of a digital image or 3D model. At
the example of three projects, the speaker will demonstrate how
careful analysis of the underlying cultural-heritage questions allows
for bespoke solutions that--through joint development of imaging
procedures, data analysis and visualisations--directly support
conservators and humanities researchers in their work. Tim Weyrich
will report on his experiences with fresco reconstruction at the
Akrotiri Excavation, Santorini, on the reconstruction of fire-damaged
parchment with London Metropolitan Archives, and on the analysis of
Egyptian papyri with the Petrie Museum in London.

**Short-Bio:** Tim Weyrich is an Associate Professor in the Virtual
  Environments and Computer Graphics group in the Department of
  Computer Science, University College London, and co-founder and
  Associate Director of the UCL Centre for Digital Humanities. Prior
  to coming to UCL, Tim was a Postdoctoral Teaching Fellow of
  Princeton University, working in the Princeton Computer Graphics
  Group, a post he took after having received his PhD from ETH Zurich,
  Switzerland, in 2006. His research interests are appearance
  modelling and fabrication, point-based graphics, 3D reconstruction,
  cultural heritage analysis and digital humanities.

## Searching for Images to Measure the World

- [Robert Pless](http://www.cse.wustl.edu/~pless), Washington University in St. Louis - USA

The world is observed by an enormous collection of cameras ---
webcams, satellites and cell-phones.  For 7 years, my group has
explored what it takes to organize internet imagery as a tool for
phenology, environmental, atmospheric and social measurement. Our
approaches to analyzing this data set are inspired by a combination of
time-lapse video artists Jason Salavon and Hiroshi Sugimoto and work
to characterize the statistical invariants in images of natural
scenes.  When possible, we share our work as web-based tools or free
apps so that more people can use Internet imagery to measure changes
in their world.  I will share some of our work to use these tools to
measure the effects of weather changes on annual plant growth
patterns, and characterizing how people use public spaces.  I will
also share unexpected successes we find from sharing these tools,
including their use in tracking turtle migration and their forensic
use to discover the location of a lost grave.

**Short-Bio:** Robert Pless is a Professor of Computer Science and
  Engineering at Washington University in St. Louis. His research
  focus is data driven approach to understanding motion and change in
  video, with a current focus on long term time-lapse
  imagery. Dr. Pless has a Bachelors Degree in Computer Science from
  Cornell University in 1994 and a PhD from the University of
  Maryland, College Park in 2000. He received the NSF CAREER award in
  2006, chaired the IEEE Workshop on Omnidirectional Vision and Camera
  Networks (OMNIVIS) in 2003, and gave a keynote address at the IEEE
  Workshop on Application of Computer Vision in 2013.

## Detectors and Descriptors for Three Dimensional Reconstruction of Real Scenes

- [Mario Campos](http://www.verlab.dcc.ufmg.br/publicacoes/author/mario_fernando_montenegro_campos), UFMG - Brazil

Three dimensional reconstruction of objects and scenes has been one of the key challenges for Computer Vision, and one of the first to be addressed by the community. Through the years impressive accomplishments have been attained by novel algorithms and innovative techniques using multiple two-dimensional images. Numerous new devices have also emerged with increased degree of resolution and accuracy. At the heart of many of such techniques is the ability to detect key points and to generate unique signatures which might enable consistent matching among images. More recently, the advent of commercially available, low cost devices has broadened the way and stirred even further the challenges of scene reconstruction by providing both image and depth information, even in real time.  In this talk we will present recent approaches that use both information to build detectors and descriptors that are robust to several environmental conditions and at the same time are computationally efficient. We will show applications of such descriptors in the reconstruction of real indoor and outdoor scenes.

**Short Bio:** Mario Fernando Montenegro Campos, Ph.D., is a Professor of Computer Vision and Robotics in the Department of Computer Science at the Federal University of Minas Gerais (UFMG), Belo Horizonte, Brazil. He holds B.S. degrees in Engineering, and M.S. in Computer Science, all from UFMG, and a Ph.D. in Computer and Information Science from the University of Pennsylvania, USA.  His research interests include cooperative robotics, robot vision, sensor information processing. His main contributions are in haptics, multirobot cooperation, aerial robotics and robot vision. He is the founder and director of the Vision and Robotics Lab -- VeRLab, UFMG, Brazil. He has been a Distinguished Lecturer in the IEEE Robotics and Automation Society.

## Deep Learning That Just Works

- [James Bergstra](http://www.eng.uwaterloo.ca/~jbergstr/), University of Waterloo - Canad√°

Deep Learning has captured the imagination of researchers in both
academia and industry after breakthrough empirical results in vision,
speech processing, and natural language processing.  However, the
success of a deep learning algorithm is highly sensitive to myriad
hyperparameters governing the data pre-processing, architecture,
initial conditions, and learning. Reproducing these results and
transferring them to new data sets is hard, even for experts, and
insufficient exploration of hyperparameter configurations can lead to
premature conclusions from successful models.  New tools and model
selection techniques based on Bayesian optimization and evolutionary
search promise a more reliable approach to the design of deep learning
systems, and machine learning systems more generally.  This talk will
describe software tools and ongoing research in computer-assisted
design of deep learning systems for big data applications. Theano
provides Graphics Processing Unit (GPU) code generation for
computer-generated model configurations, so that deep networks can be
trained in hours instead of days.  Hyperopt is a black-box
optimization library tailored for hyperparameter optimization by
e.g. evolutionary search and Bayesian optimization algorithms.
Together they demonstrate that algorithmic hyperparameter optimization
represents a viable and fully-automated strategy for configuring deep
learning architectures, and provide a new perspective on the success
of deep learning.
	 
**Short-Bio:** Dr. James Bergstra holds a Banting Postdoctoral
  Fellowship at the University of Waterloo Centre for Theoretical
  Neuroscience. His research interests include visual system models
  and learning algorithms, deep learning, Bayesian optimization, high
  performance computing, and music information retrieval. Previously
  he was a Research Scholar at the Rowland Institute for Science at
  Harvard University. He holds a doctoral degree from the University
  of Montreal with a dissertation on the use of complex cells models
  for deep learning. He co-authored Theano, a popular meta-programming
  system for Python that can target GPUs for high-performance
  computation.
