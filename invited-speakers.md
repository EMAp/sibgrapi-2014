---
layout: content
title: Invited Speakers
---

## Computational Analysis in Cultural Heritage Applications

- [Tim Weyrich](http://www0.cs.ucl.ac.uk/staff/t.weyrich/), University College London - UK

Through the increasing availability of high-quality consumer hardware
for advanced imaging tasks, digital imaging and scanning are gradually
pervading general practice in cultural heritage preservation and
archaeology. In most cases, however, imaging and scanning are
predominantly means of documentation and archival, and digital
processing ends with the creation of a digital image or 3D model. At
the example of three projects, the speaker will demonstrate how
careful analysis of the underlying cultural-heritage questions allows
for bespoke solutions that--through joint development of imaging
procedures, data analysis and visualisations--directly support
conservators and humanities researchers in their work. Tim Weyrich
will report on his experiences with fresco reconstruction at the
Akrotiri Excavation, Santorini, on the reconstruction of fire-damaged
parchment with London Metropolitan Archives, and on the analysis of
Egyptian papyri with the Petrie Museum in London.

**Short-Bio:** Tim Weyrich is an Associate Professor in the Virtual
  Environments and Computer Graphics group in the Department of
  Computer Science, University College London, and co-founder and
  Associate Director of the UCL Centre for Digital Humanities. Prior
  to coming to UCL, Tim was a Postdoctoral Teaching Fellow of
  Princeton University, working in the Princeton Computer Graphics
  Group, a post he took after having received his PhD from ETH Zurich,
  Switzerland, in 2006. His research interests are appearance
  modelling and fabrication, point-based graphics, 3D reconstruction,
  cultural heritage analysis and digital humanities.

## Searching for Images to Measure the World

- [Robert Pless](http://www.cse.wust.edu/~pless), Washington University in St. Louis - USA

The world is observed by an enormous collection of cameras ---
webcams, satellites and cell-phones.  For 7 years, my group has
explored what it takes to organize internet imagery as a tool for
phenology, environmental, atmospheric and social measurement. Our
approaches to analyzing this data set are inspired by a combination of
time-lapse video artists Jason Salavon and Hiroshi Sugimoto and work
to characterize the statistical invariants in images of natural
scenes.  When possible, we share our work as web-based tools or free
apps so that more people can use Internet imagery to measure changes
in their world.  I will share some of our work to use these tools to
measure the effects of weather changes on annual plant growth
patterns, and characterizing how people use public spaces.  I will
also share unexpected successes we find from sharing these tools,
including their use in tracking turtle migration and their forensic
use to discover the location of a lost grave.

**Short-Bio:** Robert Pless is a Professor of Computer Science and
  Engineering at Washington University in St. Louis. His research
  focus is data driven approach to understanding motion and change in
  video, with a current focus on long term time-lapse
  imagery. Dr. Pless has a Bachelors Degree in Computer Science from
  Cornell University in 1994 and a PhD from the University of
  Maryland, College Park in 2000. He received the NSF CAREER award in
  2006, chaired the IEEE Workshop on Omnidirectional Vision and Camera
  Networks (OMNIVIS) in 2003, and gave a keynote address at the IEEE
  Workshop on Application of Computer Vision in 2013.

## Detectors and Descriptors for Three Dimensional Reconstruction of Real Scenes

- [Mario Campos](http://www.verlab.dcc.ufmg.br/publicacoes/author/mario_fernando_montenegro_campos), UFMG - Brazil

## Deep Learning That Just Works

- [James Bergstra](http://www.eng.uwaterloo.ca/~jbergstr/)University of Waterloo - Canad√°

Deep Learning has captured the imagination of researchers in both
academia and industry after breakthrough empirical results in vision,
speech processing, and natural language processing.  However, the
success of a deep learning algorithm is highly sensitive to myriad
hyperparameters governing the data pre-processing, architecture,
initial conditions, and learning. Reproducing these results and
transferring them to new data sets is hard, even for experts, and
insufficient exploration of hyperparameter configurations can lead to
premature conclusions from successful models.  New tools and model
selection techniques based on Bayesian optimization and evolutionary
search promise a more reliable approach to the design of deep learning
systems, and machine learning systems more generally.  This talk will
describe software tools and ongoing research in computer-assisted
design of deep learning systems for big data applications. Theano
provides Graphics Processing Unit (GPU) code generation for
computer-generated model configurations, so that deep networks can be
trained in hours instead of days.  Hyperopt is a black-box
optimization library tailored for hyperparameter optimization by
e.g. evolutionary search and Bayesian optimization algorithms.
Together they demonstrate that algorithmic hyperparameter optimization
represents a viable and fully-automated strategy for configuring deep
learning architectures, and provide a new perspective on the success
of deep learning.
	 
**Short-Bio:** Dr. James Bergstra holds a Banting Postdoctoral
  Fellowship at the University of Waterloo Centre for Theoretical
  Neuroscience. His research interests include visual system models
  and learning algorithms, deep learning, Bayesian optimization, high
  performance computing, and music information retrieval. Previously
  he was a Research Scholar at the Rowland Institute for Science at
  Harvard University. He holds a doctoral degree from the University
  of Montreal with a dissertation on the use of complex cells models
  for deep learning. He co-authored Theano, a popular meta-programming
  system for Python that can target GPUs for high-performance
  computation.
